<div align="center">
<h1>
  Sakura-13B-Galgame
</h1>
</div>

<p align="center">
ğŸ¤— <a href="https://huggingface.co/sakuraumi/Sakura-13B-Galgame" target="_blank">Hugging Face</a> â€¢ ğŸ¤– <a href="https://www.modelscope.cn/models/sakuraumi/Sakura-13B-Galgame" target="_blank">ModelScope</a>
</p>

# ä»‹ç»

åŸºäºOpenBuddy(v0.1-v0.4), Qwen-14B(v0.7)å’ŒBaichuan2-13B(v0.5,v0.8)æ„å»ºï¼Œåœ¨é€šç”¨æ—¥æ–‡è¯­æ–™ä¸è½»å°è¯´/Galgameç­‰é¢†åŸŸçš„ä¸­æ—¥è¯­æ–™ä¸Šè¿›è¡Œå¾®è°ƒï¼Œæ—¨åœ¨æä¾›æ€§èƒ½æ¥è¿‘GPT3.5ä¸”å®Œå…¨ç¦»çº¿çš„Galgame/è½»å°è¯´ç¿»è¯‘å¤§è¯­è¨€æ¨¡å‹. æ–°å»ºäº†[TGäº¤æµç¾¤](https://t.me/+QMDKZyO9GV1kNDA1)ï¼Œæ¬¢è¿äº¤æµè®¨è®ºã€‚

# å¦‚æœä½¿ç”¨æ¨¡å‹ç¿»è¯‘å¹¶å‘å¸ƒï¼Œè¯·åœ¨æœ€æ˜¾çœ¼çš„ä½ç½®æ ‡æ³¨æœºç¿»ï¼ï¼ï¼ï¼ï¼å¼€å‘è€…å¯¹äºæ»¥ç”¨æœ¬æ¨¡å‹é€ æˆçš„ä¸€åˆ‡åæœä¸è´Ÿä»»ä½•è´£ä»»ã€‚

### ç½‘ç«™ï¼š[è½»å°è¯´æœºç¿»æœºå™¨äºº](https://books.fishhawk.top/)å·²æ¥å…¥Sakuraæ¨¡å‹(v0.8-4bit)ï¼Œç«™å†…æœ‰å¤§é‡æ¨¡å‹ç¿»è¯‘ç»“æœå¯ä¾›å‚è€ƒã€‚

è½»å°è¯´æœºç¿»æœºå™¨äººç½‘ç«™æ˜¯ä¸€ä¸ªè‡ªåŠ¨ç”Ÿæˆè½»å°è¯´æœºç¿»å¹¶åˆ†äº«çš„ç½‘ç«™ã€‚ä½ å¯ä»¥æµè§ˆæ—¥æ–‡ç½‘ç»œå°è¯´ï¼Œæˆ–è€…ä¸Šä¼ Epub/Txtæ–‡ä»¶ï¼Œå¹¶ç”Ÿæˆæœºç¿»ã€‚

### æ¨¡å‹ä¸‹è½½ï¼š
|   ç‰ˆæœ¬  | å…¨é‡æ¨¡å‹ | 8-bité‡åŒ– | 4-bité‡åŒ– | 3-bité‡åŒ– |
|:-------:|:-------:|:-------:|:-------:|:-------:|
| 20230827-v0.1 | ğŸ¤— [Sakura-13B-Galgame-v0.1](https://huggingface.co/sakuraumi/Sakura-13B-Galgame/tree/main/sakura_13b_model_v0.1) | - | - | - |
| 20230908-v0.4 | ğŸ¤— [Sakura-13B-Galgame-v0.4](https://huggingface.co/sakuraumi/Sakura-13B-Galgame/tree/main/sakura_13b_model_v0.4) | - | - | - |
| 20230917-v0.5 | ğŸ¤— [Sakura-13B-Galgame-v0.5](https://huggingface.co/sakuraumi/Sakura-13B-Galgame) | ğŸ¤— [Sakura-13B-Galgame-v0.5-8bits](https://huggingface.co/sakuraumi/Sakura-13B-Galgame/tree/main/sakura_13b_model_v0.5_8bits) | [Sakura-13B-Galgame-v0.5-4bits](https://huggingface.co/sakuraumi/Sakura-13B-Galgame/tree/main/sakura_13b_model_v0.5_4bits_autogptq_40k) | - |
| 20231011-v0.7 | ğŸ¤— [Kisara-14B-LNovel](https://huggingface.co/sakuraumi/Sakura-14B-LNovel) | - | - | - |
| 20231026-v0.8 | ğŸ¤— [Sakura-13B-LNovel-v0.8](https://huggingface.co/SakuraLLM/Sakura-13B-LNovel-v0.8) | ğŸ¤— [Sakura-13B-LNovel-v0_8-8bit](https://huggingface.co/SakuraLLM/Sakura-13B-LNovel-v0_8-8bit) | ğŸ¤— [Sakura-13B-LNovel-v0_8-4bit](https://huggingface.co/SakuraLLM/Sakura-13B-LNovel-v0_8-4bit) | ğŸ¤— [Sakura-13B-LNovel-v0_8-3bit](https://huggingface.co/SakuraLLM/Sakura-13B-LNovel-v0_8-3bit) |

ç›®å‰ä»ä¸ºå®éªŒç‰ˆæœ¬ï¼Œç¿»è¯‘è´¨é‡è¾ƒå·®. ä¸ªäººä½¿ç”¨æ¨èGPT4.

# æ˜¾å­˜éœ€æ±‚

ä½¿ç”¨v0.8ç‰ˆæœ¬è¿›è¡Œæµ‹è¯•ï¼Œæ¨¡å‹ç”Ÿæˆå‚æ•°ä¸ä»“åº“ä¸­`generation_config.json`ä¸€è‡´ï¼Œæ˜¾å­˜å ç”¨æ•°æ®å–è‡ª`nvidia-smi`

|  æ¨¡å‹é‡åŒ–ç±»å‹  | è½½å…¥æ˜¾å­˜ | æ¨ç†æ˜¾å­˜(ctxçº¦600) | æ¨ç†æ˜¾å­˜(ctxçº¦1800) |
|:-------:|:-------:|:-------:|:-------:|
| å…¨é‡ | è¶…å‡ºæ¸¸æˆæ˜¾å¡æ˜¾å­˜èŒƒå›´ | - | - |
| 8bit | 17G | 21.1G | 23.4G |
| 4bit | 11.3G | 14.9G | 17.4G |
| 3bit | 9.7G | 13.7G | 15.5G |

# å¿«é€Ÿå¼€å§‹

## Dockeréƒ¨ç½²

è¯¦è§åˆ†æ”¯`dev_server`ä¸­çš„[README.docker.md](https://github.com/SakuraLLM/Sakura-13B-Galgame/blob/dev_server/README.docker.md)

## æœ¬åœ°éƒ¨ç½²

é¦–å…ˆå°†æœ¬ä»“åº“æ‹‰å–åˆ°æœ¬åœ°ã€‚

- å¯åŠ¨APIæœåŠ¡

åˆ‡æ¢åˆ°`dev_server`åˆ†æ”¯ï¼Œè¯¥åˆ†æ”¯æä¾›äº†APIæ¥å£ï¼ˆæ„Ÿè°¢[KurikoMoe](https://github.com/kurikomoe)ï¼‰ï¼Œç”¨ä»¥æä¾›APIæœåŠ¡ï¼Œä»¥æ¥å…¥å…¶ä»–ç¨‹åºã€‚

```bash
# å‚æ•°è¯´æ˜ï¼š
# æ¨¡å‹ç›¸å…³
# --model_name_or_pathï¼šæ¨¡å‹æœ¬åœ°è·¯å¾„æˆ–è€…huggingfaceä»“åº“idã€‚
# --model_versionï¼šæ¨¡å‹ç‰ˆæœ¬ï¼Œæœ¬ä»“åº“READMEè¡¨æ ¼ä¸­å³å¯æŸ¥çœ‹ã€‚å¯é€‰èŒƒå›´ï¼š['0.1', '0.4', '0.5', '0.7', '0.8']
# --use_gptq_modelï¼šå¦‚æœæ¨¡å‹ä¸ºgptqé‡åŒ–æ¨¡å‹ï¼Œåˆ™éœ€åŠ æ­¤é¡¹ï¼›å¦‚æ˜¯å…¨é‡æ¨¡å‹ï¼Œåˆ™ä¸éœ€è¦æ·»åŠ ã€‚
# --trust_remote_codeï¼šæ˜¯å¦å…è®¸æ‰§è¡Œå¤–éƒ¨å‘½ä»¤ï¼ˆå¯¹äº0.5ï¼Œ0.7ï¼Œ0.8ç‰ˆæœ¬æ¨¡å‹éœ€è¦åŠ ä¸Šè¿™ä¸ªå‚æ•°ï¼Œå¦åˆ™æŠ¥é”™ã€‚
# --llamaï¼šå¦‚æœä½ ä½¿ç”¨çš„æ¨¡å‹æ˜¯llamaå®¶æ—çš„æ¨¡å‹ï¼ˆå¯¹äº0.1ï¼Œ0.4ç‰ˆæœ¬ï¼‰ï¼Œåˆ™éœ€è¦åŠ å…¥æ­¤å‘½ä»¤ã€‚
# APIæœåŠ¡ç›¸å…³
# --listenï¼šæŒ‡å®šè¦ç›‘å¬çš„IPå’Œç«¯å£ï¼Œæ ¼å¼ä¸º<IP>:<Port>ï¼Œå¦‚127.0.0.1:5000ã€‚é»˜è®¤ä¸º127.0.0.1:5000
# --authï¼šä½¿ç”¨è®¤è¯ï¼Œè®¿é—®APIéœ€è¦æä¾›è´¦æˆ·å’Œå¯†ç ã€‚
# --no-authï¼šä¸ä½¿ç”¨è®¤è¯ï¼Œå¦‚æœå°†APIæš´éœ²åœ¨å…¬ç½‘å¯èƒ½ä¼šé™ä½å®‰å…¨æ€§ã€‚
# --logï¼šè®¾ç½®æ—¥å¿—ç­‰çº§ã€‚
# ä¸‹é¢ä¸ºä¸€ä¸ªä½¿ç”¨v0.8-4bitæ¨¡å‹ï¼ŒåŒæ—¶ä¸ä½¿ç”¨è®¤è¯ï¼Œç›‘å¬127.0.0.1:5000çš„å‘½ä»¤ç¤ºä¾‹ã€‚
# è¿™é‡Œæ¨¡å‹é»˜è®¤ä»huggingfaceæ‹‰å–ï¼Œå¦‚æœä½ å·²ç»å°†æ¨¡å‹ä¸‹è½½è‡³æœ¬åœ°ï¼Œå¯ä»¥å°†--model_name_or_pathå‚æ•°çš„å€¼æŒ‡å®šä¸ºæœ¬åœ°ç›®å½•ã€‚
python server.py --model_name_or_path SakuraLLM/Sakura-13B-LNovel-v0_8-4bit --use_gptq_model --model_version 0.8 --trust_remote_code --no-auth
```

- ç¿»è¯‘Epubæ–‡ä»¶

ä»“åº“æä¾›äº†è„šæœ¬`translate_epub.py`ï¼ˆæ„Ÿè°¢[CjangCjengh](https://github.com/CjangCjengh)ï¼‰ï¼Œç”¨äºç¿»è¯‘Epubæ ¼å¼çš„å°è¯´ã€‚ä½¿ç”¨ç¤ºä¾‹å¦‚ä¸‹ï¼š

```bash
# å‚æ•°è¯´æ˜ï¼š
# --model_name_or_pathï¼šæ¨¡å‹æœ¬åœ°è·¯å¾„æˆ–è€…huggingfaceä»“åº“idã€‚
# --model_versionï¼šæ¨¡å‹ç‰ˆæœ¬ï¼Œæœ¬ä»“åº“READMEè¡¨æ ¼ä¸­å³å¯æŸ¥çœ‹ã€‚å¯é€‰èŒƒå›´ï¼š['0.1', '0.4', '0.5', '0.7', '0.8']
# --use_gptq_modelï¼šå¦‚æœæ¨¡å‹ä¸ºgptqé‡åŒ–æ¨¡å‹ï¼Œåˆ™éœ€åŠ æ­¤é¡¹ï¼›å¦‚æ˜¯å…¨é‡æ¨¡å‹ï¼Œåˆ™ä¸éœ€è¦æ·»åŠ ã€‚
# --text_lengthï¼šæ–‡æœ¬åˆ†å—çš„æœ€å¤§å•å—æ–‡å­—æ•°é‡ã€‚
# --data_pathï¼šæ—¥æ–‡åŸæ–‡Epubå°è¯´æ–‡ä»¶è·¯å¾„ã€‚
# --data_folderï¼šæ‰¹é‡ç¿»è¯‘Epubå°è¯´æ—¶ï¼Œå°è¯´æ‰€åœ¨çš„æ–‡ä»¶å¤¹è·¯å¾„
# --output_folderï¼šç¿»è¯‘åçš„Epubæ–‡ä»¶è¾“å‡ºè·¯å¾„ï¼ˆæ³¨æ„æ˜¯æ–‡ä»¶å¤¹è·¯å¾„ï¼‰ã€‚
# --trust_remote_codeï¼šæ˜¯å¦å…è®¸æ‰§è¡Œå¤–éƒ¨å‘½ä»¤ï¼ˆå¯¹äº0.5ï¼Œ0.7ï¼Œ0.8ç‰ˆæœ¬æ¨¡å‹éœ€è¦åŠ ä¸Šè¿™ä¸ªå‚æ•°ï¼Œå¦åˆ™æŠ¥é”™ã€‚
# --llamaï¼šå¦‚æœä½ ä½¿ç”¨çš„æ¨¡å‹æ˜¯llamaå®¶æ—çš„æ¨¡å‹ï¼ˆå¯¹äº0.1ï¼Œ0.4ç‰ˆæœ¬ï¼‰ï¼Œåˆ™éœ€è¦åŠ å…¥æ­¤å‘½ä»¤ã€‚
# ä»¥ä¸‹ä¸ºä¸€ä¸ªä¾‹å­
python translate_epub.py \
    --model_name_or_path SakuraLLM/Sakura-13B-LNovel-v0_8-4bit \
    --trust_remote_code \
    --model_version 0.8 \
    --use_gptq_model \
    --text_length 512 \
    --data_path novel.epub \
    --output_folder output
```

- ç¿»è¯‘çº¯æ–‡æœ¬

ä»“åº“æä¾›äº†è„šæœ¬`translate_novel.py`ï¼Œç”¨äºç¿»è¯‘è½»å°è¯´ç­‰çº¯æ–‡æœ¬æ ¼å¼ï¼Œæ”¯æŒè¾“å‡ºä¸­æ—¥å¯¹ç…§æ–‡æœ¬ã€‚ä½¿ç”¨ç¤ºä¾‹å¦‚ä¸‹ï¼š

```bash
# å‚æ•°è¯´æ˜ï¼š
# --model_name_or_pathï¼šæ¨¡å‹æœ¬åœ°è·¯å¾„æˆ–è€…huggingfaceä»“åº“idã€‚
# --model_versionï¼šæ¨¡å‹ç‰ˆæœ¬ï¼Œæœ¬ä»“åº“READMEè¡¨æ ¼ä¸­å³å¯æŸ¥çœ‹ã€‚å¯é€‰èŒƒå›´ï¼š['0.1', '0.4', '0.5', '0.7', '0.8']
# --use_gptq_modelï¼šå¦‚æœæ¨¡å‹ä¸ºgptqé‡åŒ–æ¨¡å‹ï¼Œåˆ™éœ€åŠ æ­¤é¡¹ï¼›å¦‚æ˜¯å…¨é‡æ¨¡å‹ï¼Œåˆ™ä¸éœ€è¦æ·»åŠ ã€‚
# --text_lengthï¼šæ–‡æœ¬åˆ†å—çš„æœ€å¤§å•å—æ–‡å­—æ•°é‡ã€‚æ¯å—æ–‡å­—é‡å°†åœ¨text_length/2è‡³text_lengthå†…éšæœºé€‰æ‹©ã€‚
# --compare_textï¼šæ˜¯å¦éœ€è¦è¾“å‡ºä¸­æ—¥å¯¹ç…§æ–‡æœ¬ï¼Œå¦‚éœ€è¦ï¼Œåˆ™éœ€åŠ æ­¤é¡¹ï¼›å¦‚ä¸éœ€è¦åˆ™ä¸è¦æ·»åŠ ã€‚
# --data_pathï¼šæ—¥æ–‡åŸæ–‡æ–‡ä»¶è·¯å¾„
# --output_pathï¼šç¿»è¯‘(æˆ–å¯¹ç…§)æ–‡æœ¬è¾“å‡ºæ–‡ä»¶è·¯å¾„
# --trust_remote_codeï¼šæ˜¯å¦å…è®¸æ‰§è¡Œå¤–éƒ¨å‘½ä»¤ï¼ˆå¯¹äº0.5ï¼Œ0.7ï¼Œ0.8ç‰ˆæœ¬æ¨¡å‹éœ€è¦åŠ ä¸Šè¿™ä¸ªå‚æ•°ï¼Œå¦åˆ™æŠ¥é”™ã€‚
# --llamaï¼šå¦‚æœä½ ä½¿ç”¨çš„æ¨¡å‹æ˜¯llamaå®¶æ—çš„æ¨¡å‹ï¼ˆå¯¹äº0.1ï¼Œ0.4ç‰ˆæœ¬ï¼‰ï¼Œåˆ™éœ€è¦åŠ å…¥æ­¤å‘½ä»¤ã€‚
# ä»¥ä¸‹ä¸ºä¸€ä¸ªä¾‹å­
python translate_novel.py \
    --model_name_or_path SakuraLLM/Sakura-13B-LNovel-v0_8-4bit \
    --trust_remote_code \
    --model_version 0.8 \
    --use_gptq_model \
    --text_length 512 \
    --data_path data.txt \
    --output_path data_translated.txt \
    --compare_text
```

# æ—¥å¿—

`20231026`ï¼šä¸Šä¼ ç¬¬äº”ç‰ˆæ¨¡å‹`sakura-13b-2epoch-3.8M-1025-v0.8`ï¼Œæ”¹å–„æ•°æ®é›†è´¨é‡ä¸æ ¼å¼ï¼Œä¿®å¤ä¹‹å‰ç‰ˆæœ¬æ¨¡å‹æ— æ³•æ­£ç¡®è§£æ\nçš„é—®é¢˜ï¼Œä½¿ç”¨Baichuan2-13B-Chatæ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚

`20231011`ï¼šä¸Šä¼ ç¬¬å››ç‰ˆæ¨¡å‹`sakura-14b-2epoch-4.4M-1003-v0.7`ï¼Œæ”¹ç”¨QWen-14B-Chatæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œé’ˆå¯¹è¾ƒé•¿æ–‡æœ¬è¿›è¡Œä¼˜åŒ–ï¼Œå¢åŠ æ•°æ®é›†ã€‚

`20230918`ï¼šä¸Šä¼ ç¬¬ä¸‰ç‰ˆæ¨¡å‹çš„8bitsé‡åŒ–ç‰ˆ`sakura-13b-2epoch-2.6M-0917-v0.5-8bits`ã€‚

`20230917`ï¼šä¸Šä¼ ç¬¬ä¸‰ç‰ˆæ¨¡å‹`sakura-13b-2epoch-2.6M-0917-v0.5`ï¼Œæ”¹ç”¨Baichuan2-13B-Chatæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œç¿»è¯‘è´¨é‡æœ‰æ‰€æé«˜ã€‚

`20230908`ï¼šä¸Šä¼ ç¬¬äºŒç‰ˆæ¨¡å‹`sakura-13b-1epoch-2.6M-0903-v0.4`ï¼Œä½¿ç”¨Galgameå’Œè½»å°è¯´æ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼Œè¯­æ³•èƒ½åŠ›æœ‰æ‰€æé«˜ã€‚æ„Ÿè°¢[CjangCjengh](https://github.com/CjangCjengh)å¤§ä½¬æä¾›è½»å°è¯´æ•°æ®é›†ã€‚

`20230827`ï¼šä¸Šä¼ ç¬¬ä¸€ç‰ˆæ¨¡å‹`sakura-13b-2epoch-260k-0826-v0.1`

# æ¨¡å‹è¯¦æƒ…

## æè¿°

### v0.1-v0.4

- Finetuned by [SakuraUmi](https://github.com/pipixia244)
- Finetuned on [Openbuddy-LLaMA2-13B](https://huggingface.co/OpenBuddy/openbuddy-llama2-13b-v8.1-fp16)
- Base model: [LLaMA2-13B](https://huggingface.co/meta-llama/Llama-2-13b-chat-hf)
- Languages: Chinese/Japanese

### v0.5

- Finetuned by [SakuraUmi](https://github.com/pipixia244)
- Finetuned on [Baichuan2-13B-Chat](https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat)
- Base model: [Baichuan2-13B-Base](https://huggingface.co/baichuan-inc/Baichuan2-13B-Base)
- Languages: Chinese/Japanese

### v0.7

- Finetuned by [SakuraUmi](https://github.com/pipixia244)
- Finetuned on [Qwen-14B-Chat](https://huggingface.co/Qwen/Qwen-14B)
- Base model: [Qwen-14B](https://huggingface.co/Qwen/Qwen-14B)
- Languages: Chinese/Japanese

### v0.8

- Finetuned by [SakuraUmi](https://github.com/pipixia244)
- Finetuned on [Baichuan2-13B-Chat](https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat)
- Base model: [Baichuan2-13B-Base](https://huggingface.co/baichuan-inc/Baichuan2-13B-Base)
- Languages: Chinese/Japanese

## ç‰ˆæœ¬

### v0.8

æ•°æ®é›†ï¼šçº¦0.25Bå­—æ•°çš„è½»å°è¯´/Galgameä¸­æ—¥å¹³è¡Œè¯­æ–™

å¾®è°ƒæ–¹å¼ï¼šå…¨å‚æ•°

å¾®è°ƒepochæ•°ï¼š2

å‚æ•°é‡ï¼š13.9B

### v0.7

æ•°æ®é›†ï¼šçº¦0.3Bå­—æ•°çš„è½»å°è¯´/Galgameä¸­æ—¥å¹³è¡Œè¯­æ–™

å¾®è°ƒæ–¹å¼ï¼šå…¨å‚æ•°

å¾®è°ƒepochæ•°ï¼š2

å‚æ•°é‡ï¼š14B

### v0.5

æ•°æ®é›†ï¼šçº¦0.17Bå­—æ•°çš„è½»å°è¯´/Galgameä¸­æ—¥å¹³è¡Œè¯­æ–™

å¾®è°ƒæ–¹å¼ï¼šå…¨å‚æ•°

å¾®è°ƒepochæ•°ï¼š2

å‚æ•°é‡ï¼š13B

### v0.4

æ•°æ®é›†ï¼šçº¦0.17Bå­—æ•°çš„è½»å°è¯´/Galgameä¸­æ—¥å¹³è¡Œè¯­æ–™

å¾®è°ƒæ–¹å¼ï¼šå…¨å‚æ•°

å¾®è°ƒepochæ•°ï¼š1

å‚æ•°é‡ï¼š13B

### v0.1

æ•°æ®é›†ï¼šçº¦10Må­—æ•°çš„Galgameä¸­æ—¥å¹³è¡Œè¯­æ–™

å¾®è°ƒæ–¹å¼ï¼šå…¨å‚æ•°

å¾®è°ƒepochæ•°ï¼š2

å‚æ•°é‡ï¼š13B

## æ•ˆæœ

- Galgame

  TBD
  
- è½»å°è¯´

  ç½‘ç«™ï¼š[è½»å°è¯´æœºç¿»æœºå™¨äºº](https://books.fishhawk.top/)å·²æ¥å…¥Sakuraæ¨¡å‹(v0.8-4bit)ï¼Œç«™å†…æœ‰å¤§é‡æ¨¡å‹ç¿»è¯‘çš„è½»å°è¯´å¯ä¾›å‚è€ƒã€‚

# æ¨ç†

- Galgameç¿»è¯‘çš„promptæ„å»ºï¼š

  - v0.1

    ```python
    input_text = "" # ç”¨æˆ·è¾“å…¥
    query = "å°†ä¸‹é¢çš„æ—¥æ–‡æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡ï¼š" + input_text
    prompt = "Human: \n" + query + "\n\nAssistant: \n"
    ```
    
  - v0.4

    ```python
    input_text = "" # ç”¨æˆ·è¾“å…¥
    query = "å°†ä¸‹é¢çš„æ—¥æ–‡æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡ï¼š" + input_text
    prompt = "User: " + query + "\nAssistant: "
    ```

  - v0.5ä¸v0.8

    ```python
    input_text = "" # ç”¨æˆ·è¾“å…¥
    query = "å°†ä¸‹é¢çš„æ—¥æ–‡æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡ï¼š" + input_text
    prompt = "<reserved_106>" + query + "<reserved_107>"
    ```
    
  - v0.7
    å‚è€ƒQwen-14B-Chatçš„promptæ„é€ æ–¹å¼ï¼š[è¿™é‡Œ](https://huggingface.co/Qwen/Qwen-14B-Chat/blob/5188dfeb4ff175705aa3a84ef9d616c70dea029b/qwen_generation_utils.py#L119)å’Œ[è¿™é‡Œ](https://github.com/hiyouga/LLaMA-Efficient-Tuning/blob/5310e4d1829f36619c8f224d09ec15eeaf7a4877/src/llmtuner/extras/template.py#L546)


- æ¨ç†ä¸è§£ç å‚æ•°ï¼š

| å‚æ•° | å€¼ |
| ---- | ---- |
| temperature | 0.1 |
| top p | 0.3 |
| do sample | True |
| beams number | 1 |
| repetition penalty | 1 |
| max new token | 512 |
| min new token | 1 |

- é‡åŒ–ï¼š

æ ¹æ®transformersæ–‡æ¡£ä¸­ç»™å‡ºçš„AutoGPTQé‡åŒ–æ•™ç¨‹è‡ªè¡Œé‡åŒ–ï¼Œæˆ–ä½¿ç”¨æˆ‘ä»¬å·²ç»é‡åŒ–å¥½çš„æ¨¡å‹ã€‚

ä½¿ç”¨é‡åŒ–æ¨¡å‹æ¨ç†çš„ç¤ºä¾‹ä»£ç ï¼š

```python
from transformers import AutoTokenizer, GenerationConfig
from auto_gptq import AutoGPTQForCausalLM

path = "path/to/your/model"
text = "" #è¦ç¿»è¯‘çš„æ–‡æœ¬

generation_config = GenerationConfig.from_pretrained(path)
tokenizer = AutoTokenizer.from_pretrained(path, use_fast=False, trust_remote_code=True)
model = AutoGPTQForCausalLM.from_quantized(path, device="cuda:0", trust_remote_code=True)

response = tokenizer.decode(model.generate(**tokenizer(f"<reserved_106>å°†ä¸‹é¢çš„æ—¥æ–‡æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡ï¼š{text}<reserved_107>", return_tensors="pt").to(model.device), generation_config=generation_config)[0]).replace("</s>", "").split("<reserved_107>")[1]
print(response)
```

# å¾®è°ƒ

æµç¨‹ä¸LLaMA2(v0.1-v0.4)/Baichuan2(v0.5ä¸v0.8)/Qwen14B(v0.7)ä¸€è‡´ï¼Œpromptæ„é€ å‚è€ƒæ¨ç†éƒ¨åˆ†

# åç»­å·¥ä½œ

1. ä¼˜åŒ–SFTæ•°æ®é›†ï¼Œæ„å»ºPTæ•°æ®é›†
2. åœ¨Base modelåŸºç¡€ä¸Šè¿›è¡Œç»§ç»­é¢„è®­ç»ƒï¼ˆæ­£åœ¨è¿›è¡Œï¼‰

# è‡´è°¢

- [CjangCjengh](https://github.com/CjangCjengh)

- [ryank231231](https://github.com/ryank231231)

- [KurikoMoe](https://github.com/kurikomoe)

- [FishHawk](https://github.com/FishHawk)

- [K024](https://github.com/K024)

- [minaduki-sora](https://github.com/minaduki-sora)

- [Kimagure7](https://github.com/Kimagure7)

- [YYF233333](https://github.com/YYF233333)

# Copyright Notice

This model is built upon Meta's LLaMA series of models and is subject to Meta's licensing agreement.

This model is intended for use only by individuals who have obtained approval from Meta and are eligible to download LLaMA.

If you have not obtained approval from Meta, you must visit the https://ai.meta.com/llama/ page, read and agree to the model's licensing agreement, submit an application, and wait for approval from Meta before downloading the model from this page.
